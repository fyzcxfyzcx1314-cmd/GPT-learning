{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f96c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28f024e",
   "metadata": {},
   "source": [
    "RoPE 不再为每个位置添加向量，而是：\n",
    "\n",
    "在向量空间中通过**旋转操作（rotation operation）**，将位置信息“编码进”向量本身。\n",
    "\n",
    "换句话说，它在计算注意力前，让 query 和 key 旋转不同角度：\n",
    "\n",
    "$$\n",
    "Q' = RoPE(Q, pos), \\quad K' = RoPE(K, pos)\n",
    "$$\n",
    "\n",
    "然后使用下式计算注意力：\n",
    "\n",
    "$$\n",
    "Attention = Q'{K'}^{T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b1c10d",
   "metadata": {},
   "source": [
    "给定一个 token 的向量：\n",
    "\n",
    "$$\n",
    "x \\in \\mathbb{R}^d\n",
    "$$\n",
    "\n",
    "RoPE 将它分成两两一组：\n",
    "\n",
    "$$\n",
    "x = [x_1, x_2, x_3, x_4, \\dots, x_{d-1}, x_d]\n",
    "$$\n",
    "\n",
    "每对：\n",
    "\n",
    "$$\n",
    "(x_{2i}, \\, x_{2i+1})\n",
    "$$\n",
    "\n",
    "表示一个二维平面。\n",
    "\n",
    "对于每个位置 $p$，给定频率向量：\n",
    "\n",
    "$$\n",
    "\\theta_i = 10000^{-\\frac{2i}{d}}\n",
    "$$\n",
    "\n",
    "RoPE 定义旋转操作为：\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x'_{2i} \\\\\n",
    "x'_{2i+1}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\cos(p \\, \\theta_i) & -\\sin(p \\, \\theta_i) \\\\\n",
    "\\sin(p \\, \\theta_i) & \\cos(p \\, \\theta_i)\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_{2i} \\\\\n",
    "x_{2i+1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "换句话说，就是让每个维度对在平面上**绕原点旋转一个角度**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e55416",
   "metadata": {},
   "source": [
    "### 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25aa70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生产旋转角度矩阵\n",
    "def rotary_pos_emb(num_tokens, seq_len):\n",
    "    dim = num_tokens // 2\n",
    "    # 频率向量\n",
    "    inv_freq = 1.0 / (10000 ** (torch.arange(0, num_tokens, 2).float() / num_tokens))\n",
    "    t = torch.arange(seq_len, dtype = torch.float)\n",
    "    # 生成频率矩阵\n",
    "    freqs = torch.einsum(\"i,j->ij\", t, inv_freq)\n",
    "    cos, sin = freqs.cos(), freqs.sin()\n",
    "    return cos, sin\n",
    "def apply_rotary_emb(x, cos, sin):\n",
    "    x1, x2 = x[..., ::2], x[..., 1::2]\n",
    "    x_rot = torch.stack((-x2, x1), dim = -1).reshape_as(x)\n",
    "    return x * cos + x_rot * sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15ef24ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (4) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, seq_len, d_model)\n\u001b[0;32m      4\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m rotary_pos_emb(d_model, seq_len)\n\u001b[1;32m----> 5\u001b[0m x_rot \u001b[38;5;241m=\u001b[39m apply_rotary_emb(x, cos[\u001b[38;5;28;01mNone\u001b[39;00m, :, :], sin[\u001b[38;5;28;01mNone\u001b[39;00m, :, :])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_rot\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m, in \u001b[0;36mapply_rotary_emb\u001b[1;34m(x, cos, sin)\u001b[0m\n\u001b[0;32m     12\u001b[0m x1, x2 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, ::\u001b[38;5;241m2\u001b[39m], x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     13\u001b[0m x_rot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack((\u001b[38;5;241m-\u001b[39mx2, x1), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape_as(x)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m cos \u001b[38;5;241m+\u001b[39m x_rot \u001b[38;5;241m*\u001b[39m sin\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (4) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "batch_size, seq_len, d_model = 2, 4, 8\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "cos, sin = rotary_pos_emb(d_model, seq_len)\n",
    "x_rot = apply_rotary_emb(x, cos[None, :, :], sin[None, :, :])\n",
    "print(x_rot.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
