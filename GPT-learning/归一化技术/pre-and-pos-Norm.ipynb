{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f859c184",
   "metadata": {},
   "source": [
    "#### PreNorm和PostNorm是Transform中的两种结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d33bc",
   "metadata": {},
   "source": [
    "### PostNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6560a64d",
   "metadata": {},
   "source": [
    "#### LayerNorm 放在 残差连接（residual）之后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b396b33",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "x = x + sublayer(x)\n",
    "x = LayerNorm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a9c7d6",
   "metadata": {},
   "source": [
    "#### 在深层模型中训练容易不稳定（梯度消失）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4360b572",
   "metadata": {},
   "source": [
    "### PreNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0988648b",
   "metadata": {},
   "source": [
    "#### LayerNorm 放在 sublayer 之前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a721536",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "x = x + sublayer(LayerNorm(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c62d0b",
   "metadata": {},
   "source": [
    "#### 梯度更稳定\n",
    "#### 更容易训练深层模型（BERT、GPT 都用这一结构）"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
